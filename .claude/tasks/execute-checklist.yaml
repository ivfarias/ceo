task:
  id: ".claude/tasks/execute-checklist.yaml"
  name: "Execute Checklist Validation"
  objective: "Systematically validate document or codebase against checklist, provide evidence for each item, generate compliance report"

  inputs:
    - name: checklist_file
      desc: "Path to checklist YAML file"
    - name: target_path
      desc: "File or directory to validate"
    - name: document
      desc: "Specific document to validate (optional)"
      default_note: "If not provided, try fuzzy match or ask user"

  flow:
    - n: 1
      title: "Setup"
      actions:
        - "Load checklist from checklist_file"
        - "If document not provided or unclear, fuzzy match similar files"
        - "If still unclear, ask user: 'Which document should I validate?'"
        - "Load target document/directory content"
        - "Extract checklist items and categories"

    - n: 2
      title: "Validate"
      critical: true
      mandate: "For EVERY checklist item, WITHOUT SKIPPING ANY:"
      for_each_item:
        actions:
          - "Read requirement carefully"
          - "Search document for evidence (quotes with line numbers)"
          - "Analyze deeply - look for explicit AND implied coverage"
          - "Check related files if directory validation"
        mark_as:
          - "✓ PASS - Requirement fully met (provide evidence)"
          - "⚠ PARTIAL - Some coverage but incomplete (explain gaps)"
          - "✗ FAIL - Not met or severely deficient (explain why)"
          - "➖ N/A - Not applicable (explain reason)"
      critical_note: "DO NOT SKIP ANY SECTIONS OR ITEMS"
      validation:
        - "Every item has status (PASS, PARTIAL, FAIL, N/A)"
        - "Evidence provided for each status"
        - "Line references included where applicable"
        - "Rationale clear for FAIL and PARTIAL"

    - n: 3
      title: "Calculate Metrics"
      actions:
        - "Count: total_applicable = items where status != N/A"
        - "Count: passed = items where status == PASS"
        - "Calculate: pass_rate = (passed / total_applicable) × 100"
        - "Categorize failed items by priority (High/Medium/Low)"

    - n: 4
      title: "Generate Report"
      actions:
        - "Create validation report in target's directory or docs/qa/reports/"
        - "Use Write tool to save report"
      report_format: |
        # Validation Report

        **Document:** {document_path}
        **Checklist:** {checklist_path}
        **Date:** {timestamp}

        ## Summary
        - Overall: {passed}/{total_applicable} passed ({pass_rate}%)
        - Critical Issues: {count}

        ## Section Results

        {For each category:}
        ### {Category Name}
        Pass Rate: {X}/{Y} ({Z}%)

        {For each item in category:}
        #### {Item Number}. {Item Description}
        **Status:** {status_icon} {status}
        **Evidence:** {quote or explanation with line numbers}
        {If FAIL/PARTIAL:}
        **Impact:** {why this matters}
        **Recommendation:** {specific fix}

        ## Failed Items

        {All ✗ items with recommendations, prioritized}

        ## Partial Items

        {All ⚠ items with what's missing}

        ## Recommendations

        1. **Must Fix (High Priority):** {critical failures}
        2. **Should Improve (Medium Priority):** {important gaps}
        3. **Consider (Low Priority):** {minor improvements}
      stop_confirm: true
      message: "Validation report generated. Review results?"

    - n: 5
      title: "Summary for User"
      actions:
        - "Present section-by-section summary"
        - "Highlight all critical issues (FAIL items)"
        - "Provide path to saved report"
        - "HALT - do not continue unless user asks"

  critical_rules:
    - "NEVER skip sections - validate EVERYTHING"
    - "ALWAYS provide evidence (quotes + line numbers) for marks"
    - "NEVER mark items as N/A to inflate pass rate"
    - "ALWAYS give specific, actionable recommendations for FAIL/PARTIAL"
    - "Think deeply about each requirement - don't rush"
    - "Save report automatically - no artifact functions"
    - "HALT after presenting summary - wait for user"
